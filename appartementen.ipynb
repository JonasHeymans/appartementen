{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "df = pd.read_pickle('files/preprocessed.pkl')\n",
    "df = df.rename(columns={\"price.mainValue\": \"Price\"}).drop('Unnamed: 0.1', axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "\n",
    "# We use the numpy fuction log1p which  applies log(1+x)\n",
    "# to all elements of the column to fix skewed features\n",
    "# Source: https://www.kaggle.com/erick5/predicting-house-prices-with-machine-learning\n",
    "\n",
    "df[\"Price\"] = np.log1p(df[\"Price\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# from scipy.stats import skew\n",
    "#\n",
    "# numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "# skewed_feats = df[numeric_feats].apply(lambda x: skew(x.dropna()))\\\n",
    "#     .sort_values(ascending=False)\n",
    "# skewness = pd.DataFrame({'Skewed Features' :skewed_feats})\n",
    "# skewness.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# skewness = skewness[abs(skewness) > 0.75]\n",
    "# print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "#\n",
    "# from scipy.special import boxcox1p\n",
    "# skewed_features = skewness.index\n",
    "# lam = 0.15\n",
    "# for feat in skewed_features:\n",
    "#     df[feat] = boxcox1p(df[feat], lam)\n",
    "#     df[feat] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]\n",
    "from sklearn.model_selection import train_test_split\n",
    "features =  list(df.drop(columns=['Price','id'],axis=1))\n",
    "X = df[features]\n",
    "y = df['Price']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "#\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "models = [\n",
    "          DecisionTreeRegressor(criterion='mse',max_depth=11),\n",
    "          GradientBoostingRegressor(n_estimators=200,max_depth=12, verbose=0),\n",
    "            RandomForestRegressor(min_samples_leaf =1, n_estimators=100,criterion='mse',max_depth=30,verbose=0),\n",
    "            xgb.XGBRegressor(colsample_bytree=0.2, gamma=0.0,\n",
    "                             learning_rate=0.05, max_depth=6,\n",
    "                             min_child_weight=1.5, n_estimators=7200,\n",
    "                             reg_alpha=0.9, reg_lambda=0.6,\n",
    "                             subsample=0.2),\n",
    "            lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "        ]\n",
    "\n",
    "\n",
    "learning_mods = pd.DataFrame()\n",
    "temp = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(max_depth=11)\n",
      "score on training 0.9503126526438037\n",
      "r2 score: 0.51 (+/- 0.15) \n",
      "Took 0.81 seconds\n",
      "\n",
      "GradientBoostingRegressor(max_depth=12, n_estimators=200)\n",
      "score on training 0.9999522192184913\n",
      "r2 score: 0.60 (+/- 0.20) \n",
      "Took 64.64 seconds\n",
      "\n",
      "RandomForestRegressor(max_depth=30)\n",
      "score on training 0.9740466190120177\n",
      "r2 score: 0.72 (+/- 0.16) \n",
      "Took 27.46 seconds\n",
      "\n",
      "XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=0.2, gamma=0.0,\n",
      "             gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "             learning_rate=0.05, max_delta_step=None, max_depth=6,\n",
      "             min_child_weight=1.5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=7200, n_jobs=None, num_parallel_tree=None,\n",
      "             random_state=None, reg_alpha=0.9, reg_lambda=0.6,\n",
      "             scale_pos_weight=None, subsample=0.2, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None)\n",
      "score on training 0.9883213324486464\n",
      "r2 score: 0.73 (+/- 0.17) \n",
      "Took 97.41 seconds\n",
      "\n",
      "LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.2319,\n",
      "              learning_rate=0.05, max_bin=55, min_data_in_leaf=6,\n",
      "              min_sum_hessian_in_leaf=11, n_estimators=720, num_leaves=5,\n",
      "              objective='regression')\n",
      "score on training 0.9156631165926625\n",
      "r2 score: 0.73 (+/- 0.19) \n",
      "Took 2.80 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inejj/anaconda3/envs/appartementen/lib/python3.7/site-packages/sklearn/feature_selection/_base.py:81: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n",
      "/Users/inejj/anaconda3/envs/appartementen/lib/python3.7/site-packages/sklearn/feature_selection/_base.py:81: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#run through models\n",
    "for model in models:\n",
    "    start = time.time()\n",
    "\n",
    "    sfm = SelectFromModel(model, threshold=0.5)\n",
    "    sfm.fit(X_train,y_train)\n",
    "    Xtrain = sfm.transform(X_train)\n",
    "    Xtest   = sfm.transform(X_test)\n",
    "\n",
    "    print(model)\n",
    "    m = str(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = cross_val_score(model, X_test, y_test, cv=5,scoring='r2')\n",
    "    print('score on training',model.score(X_train, y_train))\n",
    "    mean, std = scores.mean(), scores.std()\n",
    "    print(\"r2 score: %0.2f (+/- %0.2f)\" % (mean,std * 2),f'\\nTook '\n",
    "                                    f'{time.time() - start :.2f} 'f'seconds\\n')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "regressionTree_imp = model.feature_importances_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "data_tuples = list(zip(features,regressionTree_imp.tolist()))\n",
    "features_importance = pd.DataFrame(data_tuples, columns=['Feature','Value'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(features_importance))\n",
    "unimportant_features = features_importance[features_importance['Value'] < 20]\n",
    "features_importance = features_importance[features_importance['Value'] > 20]\n",
    "print(len(features_importance))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "1              property_netHabitableSurface\n6      E_level__primary_energy_consumption_\n9                               Living_area\n4                         Construction_year\n14                        Bedroom_1_surface\n10                      Living_room_surface\n18                          Terrace_surface\n13                         Cadastral_income\n21                         Number_of_floors\n15                        Bedroom_2_surface\n3                                 Bathrooms\n20                                  Floor__\n12                                  Toilets\n16                   Covered_parking_spaces\n0                     property_bedroomCount\n7                              Energy_class\n8                                   Facades\n180       property_location_postalCode_2100\n172       property_location_postalCode_2000\n185       property_location_postalCode_2170\n202       property_location_postalCode_2660\n141                    property_subtype_KOT\n143              property_subtype_PENTHOUSE\n166        Building_condition_To_be_done_up\n142                   property_subtype_LOFT\n164                 Building_condition_Good\n205       property_location_postalCode_2850\n2                              Armored_door\n79                                   camera\n22                                 Elevator\n139            property_subtype_FLAT_STUDIO\n173       property_location_postalCode_2018\n156             Kitchen_type_Hyper_equipped\nName: Feature, dtype: object"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_importance = features_importance.sort_values(by=['Value'], ascending=False)\n",
    "pd.set_option('display.float_format', lambda x: '%.1000f' % x)\n",
    "features_importance['Feature']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "voorspelling1 = pd.DataFrame()\n",
    "voorspelling2 = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "voorspelling1['Real'] = np.expm1(y_test).astype(int)\n",
    "voorspelling2['Voorspelling'] = np.expm1(model.predict(X_test)).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "voorspelling2.to_csv('voor.csv')\n",
    "voorspelling1.to_csv('jaja.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.2319,\n              learning_rate=0.05, max_bin=55, min_data_in_leaf=6,\n              min_sum_hessian_in_leaf=11, n_estimators=720, num_leaves=5,\n              objective='regression')"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 3456 candidates, totalling 13824 fits\n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.01, 'max_bin': 255, 'n_estimators': 24, 'num_leaves': 16, 'objective': 'regression', 'random_state': 500, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.13326043028591775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:   55.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 13824 out of 13824 | elapsed:  5.1min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005, 0.01],\n",
    "    'n_estimators': [8,16,24],\n",
    "    'num_leaves': [6,8,12,16], # large num_leaves helps improve accuracy but might lead to over-fitting\n",
    "    'boosting_type' : ['gbdt', 'dart'], # for better accuracy -> try dart\n",
    "    'objective' : ['regression'],\n",
    "    'max_bin':[255, 510], # large max_bin helps improve accuracy but might slow down training progress\n",
    "    'random_state' : [500],\n",
    "    'colsample_bytree' : [0.64, 0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(model, gridParams, verbose=1, cv=4, n_jobs=-1)\n",
    "# Run the grid\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.01, 'max_bin': 255, 'n_estimators': 24, 'num_leaves': 16, 'objective': 'regression', 'random_state': 500, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.13326043028591775\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}