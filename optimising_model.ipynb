{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "# Data analysis imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning imports\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "# Hyperopt imports\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, rand\n",
    "\n",
    "# Plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "df = pd.read_pickle('files/preprocessed.pkl')\n",
    "df = df.rename(columns={\"price.mainValue\": \"Price\"}).drop('Unnamed: 0.1', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "SEED = 314\n",
    "TEST_SIZE = 0.2\n",
    "MAX_EVALS = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "gs_hp_grid = {'max_depth':[4, 6, 8, 10],\n",
    "              'n_estimators': [10, 15, 20, 25],\n",
    "              'learning_rate': [0.2, 0.4, 0.6, 0.8],\n",
    "              'gamma': [0.2, 0.4, 0.6, 0.8]\n",
    "}\n",
    "\n",
    "hyperopt_hp_grid = {'n_estimators' : hp.quniform('n_estimators', 10, 1000, 1),\n",
    "             'learning_rate' : hp.loguniform('learning_rate', 0.001, 0.1),\n",
    "             'max_depth' : hp.quniform('max_depth', 3, 15, 1),\n",
    "             'gamma': hp.loguniform('gamma', 0.01, 1)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "mse_scorer = make_scorer(mean_squared_error)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "\n",
    "def compute_rmse(model, features, targets):\n",
    "    prediction = model.predict(features)\n",
    "    rmse = np.sqrt(mean_squared_error(targets, prediction))\n",
    "    return rmse\n",
    "\n",
    "def train_grid_search(cv_parameters, features, targets):\n",
    "    xgb_regressor = xgb.XGBRegressor()\n",
    "    grid_search = GridSearchCV(xgb_regressor, cv_parameters, cv=5,\n",
    "                               verbose=1,\n",
    "                               n_jobs=4, scoring=mse_scorer)\n",
    "    grid_search.fit(features, targets)\n",
    "    return grid_search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "def transform_params(params):\n",
    "    params[\"gamma\"] = np.log(params[\"gamma\"])\n",
    "    params[\"learning_rate\"] = np.log(params[\"learning_rate\"])\n",
    "    params[\"n_estimators\"] = int(params[\"n_estimators\"])\n",
    "    params[\"max_depth\"] = int(params[\"max_depth\"])\n",
    "    return params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "def loss(params):\n",
    "    params = transform_params(params)\n",
    "    xgb_regressor = xgb.XGBRegressor(silent=False, **params)\n",
    "    cv_mse = cross_val_score(xgb_regressor, X_train, y_train,\n",
    "                          cv=5, verbose=0, n_jobs=4,\n",
    "                          scoring=mse_scorer)\n",
    "    rmse = np.sqrt(cv_mse.mean())\n",
    "    return {'loss': rmse,\n",
    "            'status': STATUS_OK}\n",
    "def optimize(trials, space):\n",
    "    best = fmin(loss, space, algo=tpe.suggest,\n",
    "                trials=trials,\n",
    "                max_evals=MAX_EVALS)\n",
    "    return best\n",
    "def random_optimize(trials, space):\n",
    "    best = fmin(loss, space, algo=rand.suggest,\n",
    "                trials=trials,\n",
    "                max_evals=MAX_EVALS)\n",
    "    return best"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "def get_model_results(hyperparameters):\n",
    "    xgb_regressor = xgb.XGBRegressor(**hyperparameters)\n",
    "    mse_cv_scores = cross_val_score(xgb_regressor, X_train, y_train,\n",
    "                                cv=5, verbose=0,\n",
    "                                n_jobs=4, scoring=mse_scorer)\n",
    "    rmse_cv_scores = np.sqrt(mse_cv_scores)\n",
    "    xgb_regressor.fit(X_train, y_train)\n",
    "    train_rmse = compute_rmse(xgb_regressor, X_train, y_train)\n",
    "    test_rmse = compute_rmse(xgb_regressor, X_test, y_test)\n",
    "    return {'optimal_hyperparameters': hyperparameters,\n",
    "            'train_rmse': train_rmse,\n",
    "            'mean_cv_rmse' : np.sqrt(mse_cv_scores.mean()),\n",
    "            'std_cv_rmse':  mse_cv_scores.std() / float(np.sqrt(len(mse_cv_scores))),\n",
    "            'test_rmse': test_rmse}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "# df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]\n",
    "from sklearn.model_selection import train_test_split\n",
    "features =  list(df.drop(columns=['Price','id'],axis=1))\n",
    "X = df[features]\n",
    "y = df['Price']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=4)]: Done 1280 out of 1280 | elapsed:  8.4min finished\n"
     ]
    }
   ],
   "source": [
    "grid_search = train_grid_search(gs_hp_grid, X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:17<00:00, 25.73s/trial, best loss: 118063.81710633376]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "hyperopt_optimal_hp = optimize(trials, hyperopt_hp_grid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "hyperopt_optimal_hp = transform_params(hyperopt_optimal_hp)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "def get_results_df():\n",
    "    optimization_methods = ['grid_search', 'hyperopt_tpe']\n",
    "    optimal_hyperparameters= [grid_search.best_params_,\n",
    "                              hyperopt_optimal_hp]\n",
    "    results = [get_model_results(optimal_hp) for optimal_hp in optimal_hyperparameters]\n",
    "    return (pd.DataFrame(results)\n",
    "              .assign(opt_method=lambda df: pd.Series(optimization_methods))\n",
    "              .loc[:,\n",
    "                   ['optimal_hyperparameters', 'test_rmse',\n",
    "                    'mean_cv_rmse', 'std_cv_rmse',\n",
    "                    'train_rmse', 'opt_method']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "results_df = get_results_df()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "{'gamma': 0.2, 'learning_rate': 0.8, 'max_depth': 6, 'n_estimators': 25}"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['optimal_hyperparameters'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "#\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "models = [\n",
    "          DecisionTreeRegressor(criterion='mse',max_depth=11),\n",
    "          GradientBoostingRegressor(n_estimators=200,max_depth=12, verbose=0),\n",
    "            RandomForestRegressor(min_samples_leaf =1, n_estimators=100,criterion='mse',max_depth=20,verbose=0),\n",
    "            xgb.XGBRegressor(colsample_bytree=0.2, gamma=0.0,\n",
    "                             learning_rate=0.05, max_depth=6,\n",
    "                             min_child_weight=1.5, n_estimators=7200,\n",
    "                             reg_alpha=0.9, reg_lambda=0.6,\n",
    "                             subsample=0.2),\n",
    "            lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "        ]\n",
    "\n",
    "\n",
    "learning_mods = pd.DataFrame()\n",
    "temp = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(max_depth=11)\n",
      "score on training 0.9830438469004884\n",
      "r2 score: -0.30 (+/- 2.77) \n",
      "Took 0.33 seconds\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-124-51df638e7ee4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0msfm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSelectFromModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthreshold\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m     \u001B[0msfm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m     \u001B[0mXtrain\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msfm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mXtest\u001B[0m   \u001B[0;34m=\u001B[0m \u001B[0msfm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/appartementen/lib/python3.7/site-packages/sklearn/feature_selection/_from_model.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    222\u001B[0m                 \"Since 'prefit=True', call transform directly\")\n\u001B[1;32m    223\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mestimator_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 224\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mestimator_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    225\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/appartementen/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight, monitor)\u001B[0m\n\u001B[1;32m    498\u001B[0m         n_stages = self._fit_stages(\n\u001B[1;32m    499\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mraw_predictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_rng\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_val\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 500\u001B[0;31m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001B[0m\u001B[1;32m    501\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    502\u001B[0m         \u001B[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/appartementen/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001B[0m in \u001B[0;36m_fit_stages\u001B[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001B[0m\n\u001B[1;32m    555\u001B[0m             raw_predictions = self._fit_stage(\n\u001B[1;32m    556\u001B[0m                 \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mraw_predictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 557\u001B[0;31m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001B[0m\u001B[1;32m    558\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    559\u001B[0m             \u001B[0;31m# track deviance (= loss)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/appartementen/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001B[0m in \u001B[0;36m_fit_stage\u001B[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001B[0m\n\u001B[1;32m    210\u001B[0m             \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX_csr\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mX_csr\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    211\u001B[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001B[0;32m--> 212\u001B[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001B[0m\u001B[1;32m    213\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    214\u001B[0m             \u001B[0;31m# update tree leaves\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/appartementen/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[1;32m   1244\u001B[0m             \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1245\u001B[0m             \u001B[0mcheck_input\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcheck_input\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1246\u001B[0;31m             X_idx_sorted=X_idx_sorted)\n\u001B[0m\u001B[1;32m   1247\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1248\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/appartementen/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[1;32m    373\u001B[0m                                            min_impurity_split)\n\u001B[1;32m    374\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 375\u001B[0;31m         \u001B[0mbuilder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtree_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_idx_sorted\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    376\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    377\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_outputs_\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mis_classifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#run through models\n",
    "for model in models:\n",
    "    start = time.time()\n",
    "\n",
    "    sfm = SelectFromModel(model, threshold=0.5)\n",
    "    sfm.fit(X_train,y_train)\n",
    "    Xtrain = sfm.transform(X_train)\n",
    "    Xtest   = sfm.transform(X_test)\n",
    "\n",
    "    print(model)\n",
    "    m = str(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = cross_val_score(model, X_test, y_test, cv=5,scoring='r2')\n",
    "    print('score on training',model.score(X_train, y_train))\n",
    "    mean, std = scores.mean(), scores.std()\n",
    "    print(\"r2 score: %0.2f (+/- %0.2f)\" % (mean,std * 2),f'\\nTook '\n",
    "                                    f'{time.time() - start :.2f} 'f'seconds\\n')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}